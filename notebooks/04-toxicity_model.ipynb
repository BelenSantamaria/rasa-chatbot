{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fee371d-6281-4cab-b947-1b0a4b8bbf89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelo de detección de lenguaje tóxico\n",
    "\n",
    "En este notebook se explorarán varias estrategias para generar un modelo de detección de lenguaje tóxico con modelos de MAchine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ccc520-5114-41dc-a385-0935bdc5d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670dab9-902c-4aaf-8beb-4a24a94cfb59",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "El dataset utilizado será el de la competición de Kaggle traducido a catellano, además se han unificado todas las categorías referentes al lenguaje tóxico de forma que los comentarios se clasifican en toxico/no_toxico.\n",
    "\n",
    "Este dataset consta de 159571 textos de los cuáles 16225 son tóxicos. Por lo que se trata de un dataset muy desbalanceado y deberemos tenerlo en cuenta durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12da4d39-e391-4721-b4c4-93cb99bc63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'..\\data\\internal\\toxicity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b427fd-a727-4fc6-ab57-32d843ca6c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spanish_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explicación ¿Por qué las ediciones realizadas ...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! Coincide con este color de fondo con el...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey hombre, realmente no estoy tratando de edi...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" Más no puedo hacer ninguna sugerencia real s...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Usted, señor, es mi héroe. ¿Alguna posibilidad...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        spanish_text      label\n",
       "0  Explicación ¿Por qué las ediciones realizadas ...  no_toxico\n",
       "1  D'aww! Coincide con este color de fondo con el...  no_toxico\n",
       "2  Hey hombre, realmente no estoy tratando de edi...  no_toxico\n",
       "3  \" Más no puedo hacer ninguna sugerencia real s...  no_toxico\n",
       "4  Usted, señor, es mi héroe. ¿Alguna posibilidad...  no_toxico"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7348eda9-3ebb-479c-a961-3518d856da9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05690728-fcae-49a8-b882-a871a7827633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spanish_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_toxico</th>\n",
       "      <td>143346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxico</th>\n",
       "      <td>16225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           spanish_text\n",
       "label                  \n",
       "no_toxico        143346\n",
       "toxico            16225"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc56ed-b1b4-42f0-8163-d9f396741d4d",
   "metadata": {},
   "source": [
    "## Elección de la pipeline\n",
    "\n",
    "En primer lugar, utilizamos el subconjunto formado por los 10000 primeros textos para probar distintas pipelines.\n",
    "\n",
    "Compararemos las métricas obtenidas y los tiempos de entrenamiento y predicción para seleccionar la más conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fba340f-25dc-4917-b752-f4e629762e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spanish_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explicación ¿Por qué las ediciones realizadas ...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! Coincide con este color de fondo con el...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey hombre, realmente no estoy tratando de edi...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" Más no puedo hacer ninguna sugerencia real s...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Usted, señor, es mi héroe. ¿Alguna posibilidad...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Los números pueden ser listados por separado a...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>A esos dos les encanta estar en desacuerdo, ¿v...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>\"He cambiado \"\"Lance Thomas\"\" por \"\"Lance Thom...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Si bien los tribunales son, por supuesto, part...</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>¿Pero de qué se trata todo esto de Nottingham?</td>\n",
       "      <td>no_toxico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           spanish_text      label\n",
       "0     Explicación ¿Por qué las ediciones realizadas ...  no_toxico\n",
       "1     D'aww! Coincide con este color de fondo con el...  no_toxico\n",
       "2     Hey hombre, realmente no estoy tratando de edi...  no_toxico\n",
       "3     \" Más no puedo hacer ninguna sugerencia real s...  no_toxico\n",
       "4     Usted, señor, es mi héroe. ¿Alguna posibilidad...  no_toxico\n",
       "...                                                 ...        ...\n",
       "9995  Los números pueden ser listados por separado a...  no_toxico\n",
       "9996  A esos dos les encanta estar en desacuerdo, ¿v...  no_toxico\n",
       "9997  \"He cambiado \"\"Lance Thomas\"\" por \"\"Lance Thom...  no_toxico\n",
       "9998  Si bien los tribunales son, por supuesto, part...  no_toxico\n",
       "9999     ¿Pero de qué se trata todo esto de Nottingham?  no_toxico\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf50c0ec-649e-481d-8094-e7d3dabe57b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spanish_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_toxico</th>\n",
       "      <td>8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxico</th>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           spanish_text\n",
       "label                  \n",
       "no_toxico          8970\n",
       "toxico             1030"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10000].groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20124f63-55c4-432a-b2f1-14142fe22fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(list(df[:10000]['spanish_text']), df[:10000]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c99504-8b9e-443d-ac00-8243b58faf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report for ('CountVectorizer', 'SVC')\n",
      "train time: 12.164035081863403\n",
      "pred time: 3.6381349563598633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no_toxico       0.96      0.79      0.87      2248\n",
      "      toxico       0.28      0.71      0.40       252\n",
      "\n",
      "    accuracy                           0.78      2500\n",
      "   macro avg       0.62      0.75      0.63      2500\n",
      "weighted avg       0.89      0.78      0.82      2500\n",
      "\n",
      "report for ('CountVectorizer', 'LogisticRegression')\n",
      "train time: 1.7707929611206055\n",
      "pred time: 0.1160576343536377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no_toxico       0.95      0.95      0.95      2248\n",
      "      toxico       0.58      0.58      0.58       252\n",
      "\n",
      "    accuracy                           0.91      2500\n",
      "   macro avg       0.76      0.77      0.77      2500\n",
      "weighted avg       0.92      0.91      0.92      2500\n",
      "\n",
      "report for ('TfidfVectorizer', 'SVC')\n",
      "train time: 16.139720916748047\n",
      "pred time: 4.2620625495910645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no_toxico       0.93      0.99      0.96      2248\n",
      "      toxico       0.82      0.37      0.51       252\n",
      "\n",
      "    accuracy                           0.93      2500\n",
      "   macro avg       0.88      0.68      0.74      2500\n",
      "weighted avg       0.92      0.93      0.92      2500\n",
      "\n",
      "report for ('TfidfVectorizer', 'LogisticRegression')\n",
      "train time: 0.6056554317474365\n",
      "pred time: 0.11120319366455078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no_toxico       0.96      0.93      0.95      2248\n",
      "      toxico       0.51      0.62      0.56       252\n",
      "\n",
      "    accuracy                           0.90      2500\n",
      "   macro avg       0.74      0.78      0.75      2500\n",
      "weighted avg       0.91      0.90      0.91      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "results = []\n",
    "\n",
    "def get_name(o):\n",
    "    return o.__class__.__name__\n",
    "\n",
    "for lang in [CountVectorizer(), TfidfVectorizer()]:\n",
    "    for mod in [SVC(class_weight='balanced'), LogisticRegression(solver='liblinear', class_weight='balanced')]:\n",
    "        pipe = Pipeline([\n",
    "            (\"feat\", lang),\n",
    "            (\"mod\", mod)\n",
    "        ])\n",
    "        models[get_name(lang), get_name(mod)] = pipe\n",
    "        tic = time.time()\n",
    "        pipe.fit(list(x_train), y_train)\n",
    "        toc = time.time() \n",
    "        print(f\"report for {get_name(lang), get_name(mod)}\")\n",
    "        train_time = toc - tic\n",
    "        print(f\"train time: {train_time}\")\n",
    "        tic = time.time()\n",
    "        y_pred = pipe.predict(x_test)\n",
    "        toc = time.time()\n",
    "        print(f\"pred time: {toc - tic}\")\n",
    "        d = classification_report(y_test, y_pred, output_dict=True)\n",
    "        data = {\n",
    "            'lang': get_name(lang), \n",
    "            'mod': get_name(mod),\n",
    "            'precision': d['toxico']['precision'], \n",
    "            'recall': d['toxico']['recall'],\n",
    "            'pred-time': toc - tic,\n",
    "            'train-time': train_time\n",
    "            \n",
    "        }\n",
    "        results.append(data)\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497cc83-6ad1-4d06-8458-c5765ff101b7",
   "metadata": {},
   "source": [
    "## Entrenamiento con todos los datos\n",
    "\n",
    "Comaparndo los resultados obtenidos para cada pipeline, utilizaremos ('CountVectorizer', 'LogisticRegression'), ya que se obtienen practicamente las mismas métricas que con ('TfidfVectorizer', 'LogisticRegression') pero con un tiempo de predicción mucho menor. Esto favorecerá que el asistente pueda determinar si el texto introducido por el usuario es tóxico en un tiempo menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268612f2-b019-4a88-96e9-bd63ddb707a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(list(df['spanish_text']), df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8c93e36-2506-4d4f-80bf-48f4f8ce0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        (\"feat\", CountVectorizer()),\n",
    "        (\"model\", LogisticRegression(solver='liblinear', class_weight=\"balanced\"))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c57b87-c49a-4723-9554-d080fa0d22ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 21.56556510925293\n",
      "pred time: 1.9688425064086914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   no_toxico       0.98      0.93      0.95     35798\n",
      "      toxico       0.57      0.81      0.67      4095\n",
      "\n",
      "    accuracy                           0.92     39893\n",
      "   macro avg       0.77      0.87      0.81     39893\n",
      "weighted avg       0.94      0.92      0.92     39893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "pipe.fit(list(x_train), y_train)\n",
    "toc = time.time() \n",
    "train_time = toc - tic\n",
    "print(f\"train time: {train_time}\")\n",
    "tic = time.time()\n",
    "y_pred = pipe.predict(x_test)\n",
    "toc = time.time()\n",
    "print(f\"pred time: {toc - tic}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a19a247d-d536-440f-97af-90ffc5fe8d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\data\\\\models\\\\toxicity_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe, r'..\\data\\models\\toxicity_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e02174a-508e-4db9-9272-0f7a6d3a9016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['toxico'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict([\"Lo has hecho de puta madre!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b9a63-8426-47d7-8ba1-af97ebe13f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rasa-chatbot)",
   "language": "python",
   "name": "rasa-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
